{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Core Learning Algorithm- Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3lZkXoNcr_w"
      },
      "source": [
        "We need to predict the flower as below from some properties.\n",
        "1. Laliguras\n",
        "2. Suryamukhi\n",
        "3. Rose\n",
        "\n",
        "As above they all have properties like sepal and petal's length and widht.\n",
        "We need to classify the flower from the dataset given as above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK561hi3dUx4"
      },
      "source": [
        "from __future__ import absolute_import,division,print_function,unicode_literals\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "csv_attribute=['SepalWidth','SepalLength','PetalLength','PetalWidth','Species']\n",
        "species=['Laliguras','Suryamukhi','Rose']\n",
        "\n",
        "trainDataPath=tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\",\"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "testDataPath=tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\",\"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "trainData=pd.read_csv(trainDataPath, names=csv_attribute,header=0)\n",
        "testData=pd.read_csv(testDataPath, names=csv_attribute,header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0Racqhrvf9oU",
        "outputId": "2ef1a855-fedf-4e96-fed1-95563a9a32b5"
      },
      "source": [
        "trainData_y=trainData.pop('Species') #Finding of the DataSet\n",
        "testData_y=testData.pop('Species')#Finding of the DataSet\n",
        "\n",
        "trainData.head()\n",
        "# testData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalWidth  SepalLength  PetalLength  PetalWidth\n",
              "0         6.4          2.8          5.6         2.2\n",
              "1         5.0          2.3          3.3         1.0\n",
              "2         4.9          2.5          4.5         1.7\n",
              "3         4.9          3.1          1.5         0.1\n",
              "4         5.7          3.8          1.7         0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfVnwp0LhGEX"
      },
      "source": [
        "def input_fn(features,labels,training=True,batch_size=256):\n",
        "  dataset=tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
        "  if training:\n",
        "    dataset=dataset.shuffle(1000).repeat()\n",
        "  return dataset.batch(batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00gTBl83iBPp",
        "outputId": "e4bb117e-e716-4d0e-c24a-ae0817736fdd"
      },
      "source": [
        "feature_columns=[]\n",
        "for key in trainData.keys():\n",
        "  feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "print(feature_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ogeMuYqPi6EO",
        "outputId": "3665c727-34c8-473d-afb8-3d9256af84b0"
      },
      "source": [
        "#Main Running classification model\n",
        "from __future__ import absolute_import,division,print_function,unicode_literals\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "csv_attribute=['SepalWidth','SepalLength','PetalLength','PetalWidth','Species']\n",
        "species=['Laliguras','Suryamukhi','Rose']\n",
        "\n",
        "trainDataPath=tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\",\"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "testDataPath=tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\",\"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "trainData=pd.read_csv(trainDataPath, names=csv_attribute,header=0)\n",
        "testData=pd.read_csv(testDataPath, names=csv_attribute,header=0)\n",
        "trainData_y=trainData.pop('Species') #Finding of the DataSet\n",
        "testData_y=testData.pop('Species')#Finding of the DataSet\n",
        "def input_fn(features,labels,training=True,batch_size=256):\n",
        "  dataset=tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
        "  if training:\n",
        "    dataset=dataset.shuffle(1000).repeat()\n",
        "  return dataset.batch(batch_size)\n",
        "feature_columns=[]\n",
        "for key in trainData.keys():\n",
        "  feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "\n",
        "# Yo veneko chai k ho vanda \n",
        "# featrue columns takes the columns hidden units are the nodes with all layers and n classes are the category of species in this case\n",
        "classifier=tf.estimator.DNNClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    hidden_units=[30,10],\n",
        "    n_classes=3) \n",
        "classifier.train(\n",
        "    input_fn=lambda:input_fn(trainData,trainData_y,training=True),steps=5000\n",
        ")\n",
        "#Testing Test Dataset accuracy\n",
        "result=classifier.evaluate(input_fn=lambda:input_fn(testData,testData_y,training=False))\n",
        "#Performing Prediction\n",
        "def new_inp_fn(features,batch_size=256):\n",
        "  return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "features=['SepalWidth','SepalLength','PetalLength','PetalWidth']\n",
        "predict={}\n",
        "print(\"Enter the flower information: \")\n",
        "for f in features:\n",
        "  valid=True\n",
        "  while valid:\n",
        "    val=input(f+\": \")\n",
        "    if not val.isdigit(): valid=False\n",
        "  predict[f]= [float(val)]\n",
        "prediction=classifier.predict(new_inp_fn=lambda: new_inp_fn(predict))\n",
        "# print(prediction)\n",
        "# Ramro para ma dekhaune \n",
        "for p in prediction:\n",
        "  print(\"Class is {}\",p['class_ids'][0])\n",
        "  print(\"Probablity of being this class is {}\",p['probabilities'][0]*100)\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzc7oq8ow\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpzc7oq8ow', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpzc7oq8ow/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 3.588536, step = 0\n",
            "INFO:tensorflow:global_step/sec: 396.779\n",
            "INFO:tensorflow:loss = 2.1380353, step = 100 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.367\n",
            "INFO:tensorflow:loss = 1.7216272, step = 200 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.759\n",
            "INFO:tensorflow:loss = 1.4264107, step = 300 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 474.305\n",
            "INFO:tensorflow:loss = 1.2642496, step = 400 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.429\n",
            "INFO:tensorflow:loss = 1.1558735, step = 500 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.542\n",
            "INFO:tensorflow:loss = 1.0573035, step = 600 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.33\n",
            "INFO:tensorflow:loss = 0.99817914, step = 700 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.492\n",
            "INFO:tensorflow:loss = 1.0131943, step = 800 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.583\n",
            "INFO:tensorflow:loss = 0.9499365, step = 900 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.247\n",
            "INFO:tensorflow:loss = 0.9280826, step = 1000 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 456.745\n",
            "INFO:tensorflow:loss = 0.898435, step = 1100 (0.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 509.876\n",
            "INFO:tensorflow:loss = 0.8695165, step = 1200 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 494.656\n",
            "INFO:tensorflow:loss = 0.8479535, step = 1300 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.162\n",
            "INFO:tensorflow:loss = 0.82765764, step = 1400 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.847\n",
            "INFO:tensorflow:loss = 0.80575967, step = 1500 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.847\n",
            "INFO:tensorflow:loss = 0.80441326, step = 1600 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.368\n",
            "INFO:tensorflow:loss = 0.79126287, step = 1700 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 488.506\n",
            "INFO:tensorflow:loss = 0.78011954, step = 1800 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.531\n",
            "INFO:tensorflow:loss = 0.77134615, step = 1900 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.813\n",
            "INFO:tensorflow:loss = 0.7495506, step = 2000 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.762\n",
            "INFO:tensorflow:loss = 0.7579783, step = 2100 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 498.84\n",
            "INFO:tensorflow:loss = 0.74209416, step = 2200 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.037\n",
            "INFO:tensorflow:loss = 0.7281391, step = 2300 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.432\n",
            "INFO:tensorflow:loss = 0.7365444, step = 2400 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.367\n",
            "INFO:tensorflow:loss = 0.7308521, step = 2500 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.719\n",
            "INFO:tensorflow:loss = 0.7140141, step = 2600 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.855\n",
            "INFO:tensorflow:loss = 0.72902715, step = 2700 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.953\n",
            "INFO:tensorflow:loss = 0.7177894, step = 2800 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.002\n",
            "INFO:tensorflow:loss = 0.71065736, step = 2900 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.172\n",
            "INFO:tensorflow:loss = 0.7112721, step = 3000 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.431\n",
            "INFO:tensorflow:loss = 0.7189749, step = 3100 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 475.805\n",
            "INFO:tensorflow:loss = 0.70196927, step = 3200 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.588\n",
            "INFO:tensorflow:loss = 0.70679045, step = 3300 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 519.87\n",
            "INFO:tensorflow:loss = 0.71046627, step = 3400 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.653\n",
            "INFO:tensorflow:loss = 0.70963496, step = 3500 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 472.763\n",
            "INFO:tensorflow:loss = 0.6933137, step = 3600 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.324\n",
            "INFO:tensorflow:loss = 0.70377165, step = 3700 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 478.032\n",
            "INFO:tensorflow:loss = 0.6904197, step = 3800 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 462.919\n",
            "INFO:tensorflow:loss = 0.68881345, step = 3900 (0.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 483.899\n",
            "INFO:tensorflow:loss = 0.69665515, step = 4000 (0.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 459.81\n",
            "INFO:tensorflow:loss = 0.6651102, step = 4100 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 489.357\n",
            "INFO:tensorflow:loss = 0.68928725, step = 4200 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 471.195\n",
            "INFO:tensorflow:loss = 0.6840315, step = 4300 (0.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.473\n",
            "INFO:tensorflow:loss = 0.7061456, step = 4400 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.833\n",
            "INFO:tensorflow:loss = 0.6835437, step = 4500 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.275\n",
            "INFO:tensorflow:loss = 0.64943975, step = 4600 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 460.654\n",
            "INFO:tensorflow:loss = 0.68240654, step = 4700 (0.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.406\n",
            "INFO:tensorflow:loss = 0.6908266, step = 4800 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.935\n",
            "INFO:tensorflow:loss = 0.66090304, step = 4900 (0.204 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpzc7oq8ow/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.68175197.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-06-27T13:40:14\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpzc7oq8ow/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.22725s\n",
            "INFO:tensorflow:Finished evaluation at 2021-06-27-13:40:14\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.73333335, average_loss = 0.6946486, global_step = 5000, loss = 0.6946486\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpzc7oq8ow/model.ckpt-5000\n",
            "Enter the flower information: \n",
            "SepalWidth: 1.1\n",
            "SepalLength: 2.3\n",
            "PetalLength: 3.4\n",
            "PetalWidth: 2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-8a3585bb0668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_inp_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_inp_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;31m# print(prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Ramro para ma dekhaune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'new_inp_fn'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S74EeQnMmVFG",
        "outputId": "7550285f-9a07-42f4-dae1-e60e626925e4"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-06-27T13:39:31\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8djtwk3q/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.22612s\n",
            "INFO:tensorflow:Finished evaluation at 2021-06-27-13:39:31\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8333333, average_loss = 0.48497072, global_step = 5000, loss = 0.48497072\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmp8djtwk3q/model.ckpt-5000\n",
            "{'accuracy': 0.8333333, 'average_loss': 0.48497072, 'loss': 0.48497072, 'global_step': 5000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlZ62RchnGT7",
        "outputId": "2b21ef2c-2bcc-4f99-b931-690a37d459b9"
      },
      "source": [
        "#Performing Prediction\n",
        "def input_fn(features,batch_size=256):\n",
        "  return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "features=['SepalWidth','SepalLength','PetalLength','PetalWidth']\n",
        "predict={}\n",
        "print(\"Enter the flower information: \")\n",
        "for f in features:\n",
        "  valid=True\n",
        "  while valid:\n",
        "    val=input(f+\": \")\n",
        "    if not val.isdigit(): valid=False\n",
        "  predict[f]= [float(val)]\n",
        "prediction=classifier.predict(input_fn=lambda: input_fn(predict))\n",
        "\n",
        "for p in prediction:\n",
        "  print(\"Class is \"+species[p['class_ids'][0]])\n",
        "  a=p['probabilities'][p['class_ids']]*100\n",
        "  print(\"Probablity of being this class is \"+str(a))\n",
        "\n",
        "# print(prediction)\n",
        "# Ramro para ma dekhaune "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the flower information: \n",
            "SepalWidth: 2\n",
            "SepalWidth: 2\n",
            "SepalWidth: 2\n",
            "SepalWidth: 2\n",
            "SepalWidth: 5.6\n",
            "SepalLength: 6.4\n",
            "PetalLength: 6.5\n",
            "PetalWidth: 6.7\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpzc7oq8ow/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Class is Suryamukhi\n",
            "Probablity of being this class is [88.284775]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}